# -*- coding: utf-8 -*-
"""final code - Kylie Sankar

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3unWe2k47vu14L4XW8hseAT0MC6iIq5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, silhouette_score
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import plotly.graph_objs as go
from itertools import combinations
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error

# Reads data from CSV into DataFrame.
def ReadData(filepath):
    """ Load data from a file path into a pandas DataFrame. """
    df = pd.read_csv(filepath)
    return df

# Cleans DataFrame by removing rows with missing values.
def CleanData(dataframe):
    """ Remove rows with any missing values in DataFrame. """
    dataframe.dropna(inplace=True)
    return dataframe

# Generates descriptive statistics.
def SummaryStatistics(dataframe):
    """ Generate descriptive statistics which summarize the central tendency, dispersion, and shape of a datasetâ€™s distribution. """
    return dataframe.describe().transpose() # Transpose for better readability in output.

# Plots the distribution of a specific column.
def PlotDistribution(dataframe, column, plot_type='histogram'):
    """ Plot a histogram or boxplot for the specified column in the DataFrame. """
    plt.figure(figsize=(10, 6))
    if plot_type == 'histogram':
        sns.histplot(dataframe[column], kde=True)  # Plot with kernel density estimate
    elif plot_type == 'boxplot':
        sns.boxplot(x=dataframe[column])  # Standard boxplot
    plt.title(f'Distribution of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency' if plot_type == 'histogram' else 'Value')
    plt.grid(True)
    plt.show()

# Computes and returns correlation matrices.
def ComputeCorrelationMatrix(dataframe):
    """ Compute and return Pearson, Kendall, and Spearman correlation matrices. """
    return {method: dataframe.corr(method=method) for method in ['pearson', 'kendall', 'spearman']}# Dictionary comprehension to compute correlation matrices.


# Displays a heatmap of the correlation matrix.
def PlotCorrelationHeatmap(correlation_matrix, method):
    """ Plot a heatmap for the correlation matrix to visualize the correlation coefficients. """
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title(f'{method.capitalize()} Correlation Heatmap')
    plt.show()

# Creates interaction features between selected channels.
def CreateInteractionFeatures(dataframe):
    """ Create interaction features by multiplying selected channels and adding a total spend column. """
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    for i, channel1 in enumerate(channels):
        for j in range(i + 1, len(channels)):
            channel2 = channels[j]
            feature_name = f"{channel1}_{channel2}" # Create a new feature name based on the channels.
            dataframe[feature_name] = dataframe[channel1] * dataframe[channel2] # Multiply the columns and assign to new column.
    dataframe['Total_Spend'] = dataframe[channels].sum(axis=1)# Sum the values across the specified channels.
    return dataframe, dataframe.columns.tolist() #Return the updated DataFrame and a list of its column names.

# Trains multiple regression models and evaluates their performance.
def TrainMultipleModels(dataframe, dependent_var, feature_list):
    """ Train Linear Regression, Decision Tree, and SVR models and evaluate their performance. """
    X = dataframe[feature_list]
    y = dataframe[dependent_var]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    models = {'LinearRegression': LinearRegression(),
              'DecisionTreeRegressor': DecisionTreeRegressor(),
              'SVR': SVR()}
    model_performance = {}
    for name, model in models.items():
        model.fit(X_train, y_train) # Fit model on training data.
        predictions = model.predict(X_test) # Predict on testing data.
        model_performance[name] = {
            'R_squared': r2_score(y_test, predictions),
            'RMSE': mean_squared_error(y_test, predictions, squared=False),
            'model': model
        }
    return model_performance # Store the trained model

# Selects the best model based on RMSE.
def SelectBestModel(model_performance):
    """ Select the model with the lowest RMSE as the best model. """
    best_model, best_metric = None, float('inf') # Initialize best_model as None and best_metric as infinity.
    for model_name, metrics in model_performance.items():
        if metrics['RMSE'] < best_metric: # Compare RMSE to find the lowest one.
            best_model, best_metric = model_name, metrics['RMSE']
    return best_model, model_performance[best_model]

# Performs a t-test between two columns to compare their means.
def PerformTTest(dataframe, column1, column2):
    """ Perform a t-test between two numerical columns to compare their means statistically. """
    group1 = dataframe[column1].dropna()
    group2 = dataframe[column2].dropna()
    _, p_value = stats.ttest_ind(group1, group2, equal_var=False)
    return p_value

# Clusters data based on specified features and plots the clusters.
def KMeansClustering(dataframe, feature1, feature2, max_clusters=10):
    """ Apply KMeans clustering based on two specified features and determine the optimal number of clusters using silhouette scores. """
    data = dataframe[[feature1, feature2]]
    n_init = 10  # To suppress future warning and set n_init explicitly
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(data)
    silhouette_scores = []
    for k in range(2, max_clusters+1):
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=n_init)
        labels = kmeans.fit_predict(data_scaled)
        score = silhouette_score(data_scaled, labels)
        silhouette_scores.append(score)
    optimal_clusters = np.argmax(silhouette_scores) + 2
    final_kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
    labels = final_kmeans.fit_predict(data_scaled)
    dataframe['Cluster_Labels'] = labels
    return optimal_clusters, labels

# Plots the clustering results on a scatter plot.
def PlotClusters(dataframe, feature1, feature2, labels):
    """ Plot clusters of two features using a scatter plot with colored cluster labels. """
    plt.figure(figsize=(10, 6))
    plt.scatter(dataframe[feature1], dataframe[feature2], c=labels, cmap='viridis')
    plt.title(f'Clusters of {feature1} vs {feature2}')
    plt.xlabel(feature1)
    plt.ylabel(feature2)
    plt.show()

# Simulates the impact of advertising budgets on sales.
def SimulateAdvertisingImpact(dataframe, best_model, feature_list):
    """ Simulate and plot the impact of increasing advertising budgets on sales predictions using the best model. """
    simulation_df = dataframe.copy()  # Make a copy of the DataFrame to modify.
    for increase in range(1, 11):  # Loop to simulate increases from 10% to 100%.
        for column in feature_list:
            simulation_df[column] *= (1 + increase * 0.1)  # Increase budget by 10% increments.
        simulation_df[f'Simulated_Sales_{increase*10}%'] = best_model.predict(simulation_df[feature_list])  # Predict sales with increased budget.
        for column in feature_list:
            simulation_df[column] /= (1 + increase * 0.1)  # Reset budgets to original for next iteration.
    return simulation_df  # Return DataFrame with simulated sales data.

# Creates a Sankey diagram to visualize the flow of advertising budget to sales.
def PlotSankeyDiagram(dataframe):
    """ Create a Sankey diagram to visualize the flow of advertising budget to sales. """
    channel_sums = dataframe[['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']].sum()  # Sum of budgets.
    labels = list(channel_sums.index) + ['Sales ($)']  # Labels for the nodes in the diagram.
    source = [labels.index(ch) for ch in channel_sums.index]  # Source nodes for the links.
    target = [labels.index('Sales ($)')] * len(channel_sums)  # Target node for all links.
    values = channel_sums.values.tolist()  # Values for the links.
    fig = go.Figure(data=[go.Sankey(
        node=dict(pad=15, thickness=20, line=dict(color="black", width=0.5), label=labels),  # Node properties.
        link=dict(source=source, target=target, value=values))])  # Link properties.
    fig.update_layout(title_text="Sankey Diagram of Advertising Spend to Sales", font_size=15)  # Layout properties.
    fig.show()  # Display the Sankey diagram.

#plots the total spent in advertising vs sales
def plot_dynamic_visualization(dataframe):
    """Creates an interactive scatter plot of total advertising spend versus product sales."""
    if 'Total_Spend' not in dataframe.columns:
        dataframe['Total_Spend'] = dataframe[['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']].sum(axis=1)
    fig = px.scatter(dataframe, x='Total_Spend', y='Sales ($)', size='Sales ($)', title='Total Spend vs Sales with Regression Trend Line', trendline='ols')
    fig.show()

# Plots scatter plots for each advertising channel against sales.
def plot_each_visualization(dataframe):
    """ Plot scatter plots for each advertising channel against sales with regression trend lines. """
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    for item in channels:
        fig = px.scatter(dataframe, x=item, y='Sales ($)', size='Sales ($)',
                         title=f'{item} vs Sales with Regression Trend Line', trendline='ols')
        fig.show()

# Plots the importance of features from a model.
def plot_feature_importance(model, feature_names):
    """ Plot a bar graph of feature importances from a regression model. """
    if hasattr(model, 'feature_importances_'):  # Check if model has attribute 'feature_importances_'.
        importances = model.feature_importances_  # Get feature importances.
        indices = np.argsort(importances)[::-1]  # Sort the importances in descending order.
        plt.figure(figsize=(12, 6))  # Set figure size.
        plt.title('Feature Importances')  # Set title.
        plt.bar(range(len(importances)), importances[indices], color='b', align='center')  # Create a bar chart.
        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)  # Set x-axis labels with feature names.
        plt.xlabel('Feature')  # Label for x-axis.
        plt.ylabel('Importance')  # Label for y-axis.
        plt.show()  # Display the plot.

# Plots the residuals of a regression model.
def plot_residuals(model, X, y):
    """ Plot a scatter plot of residuals vs. predicted values from a regression model. """
    predictions = model.predict(X)  # Get predictions from the model.
    residuals = y - predictions  # Calculate residuals as actual minus predicted values.
    plt.figure(figsize=(10, 6))  # Set figure size.
    plt.scatter(predictions, residuals)  # Create scatter plot of predicted values vs residuals.
    plt.title('Residuals vs Predicted')  # Set title.
    plt.xlabel('Predicted')  # Label for x-axis.
    plt.ylabel('Residuals')  # Label for y-axis.
    plt.axhline(y=0, color='r', linestyle='--')  # Draw a horizontal line at zero for reference.
    plt.show()  # Display the plot.

# Plots scatter plots of each channel against sales on the same axis.
def plot_all_channels_vs_sales(dataframe, sales_column, channel_columns):
    """ Plot scatter plots of each channel against sales on the same axis, each in a different color. """
    plt.figure(figsize=(10, 6))  # Set figure size.
    for channel in channel_columns:  # Loop through each channel.
        sns.scatterplot(x=dataframe[channel], y=dataframe[sales_column], label=channel)  # Create scatter plot for each channel.
    plt.title('Advertising Channels vs Sales')  # Set title.
    plt.xlabel('Ad Budget ($)')  # Label for x-axis.
    plt.ylabel(sales_column)  # Label for y-axis.
    plt.legend()  # Display legend.
    plt.show()  # Display the plot.

# Print model validation metrics.
def model_validation_metrics(model, X_test, y_test):
    """ Print R-squared, RMSE, MAE, and MAPE for a given model and test data. """
    predictions = model.predict(X_test)
    print(f'R-squared: {r2_score(y_test, predictions)}')
    print(f'RMSE: {mean_squared_error(y_test, predictions, squared=False)}')
    print(f'MAE: {mean_absolute_error(y_test, predictions)}')
    print(f'MAPE: {mean_absolute_percentage_error(y_test, predictions)}')

def advertising_combinations_impact(df, channels):
    # Create a dictionary to hold the results
    combination_sales_impact = {}
    temp_df = df.copy()  # Create a copy of the dataframe

    # Iterate through all combinations of channels
    for i in range(1, len(channels) + 1):
        for combo in combinations(channels, i):
            # Create a feature name for the combination
            feature_name = '_'.join(combo)
            # Sum the spend for the current combination
            temp_df[feature_name] = temp_df[list(combo)].sum(axis=1)

            # Fit a linear regression model
            model = LinearRegression()
            model.fit(temp_df[[feature_name]], temp_df['Sales ($)'])

            # Store the coefficient (impact) of the combination
            combination_sales_impact[feature_name] = model.coef_[0]

    return combination_sales_impact

def allocate_optimal_budget(model, total_budget, feature_names):
    """Allocate budget based on model type and attributes (coefficients or feature importances)."""
    if hasattr(model, 'coef_'):  # Check if model has coefficients (linear models)
        # Linear Model
        coefficients = model.coef_
        total_influence = sum(abs(coeff) for coeff in coefficients)
        budget_allocation = {name: (coeff / total_influence) * total_budget for name, coeff in zip(feature_names, coefficients)}
    elif hasattr(model, 'feature_importances_'):  # Check if model has feature importances (tree-based models)
        # Decision Tree Model
        importances = model.feature_importances_
        total_importance = sum(importances)
        budget_allocation = {name: (importance / total_importance) * total_budget for name, importance in zip(feature_names, importances)}
    else:
        # Other models
        print("Model type not supported for automated budget allocation.")
        return None

    return budget_allocation

def predict_user_input_sales(model):
    """Function to predict sales based on user input for advertising spend."""
    # Dictionary to store user inputs
    user_inputs = {}
    # List of advertising channels
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']

    # Collect user input for each channel
    for channel in channels:
        while True:
            try:
                # Asking user input and converting it to float
                budget = float(input(f"Enter your {channel}: "))
                user_inputs[channel] = budget
                break  # Break the loop if the input is successfully converted to float
            except ValueError:
                print("Invalid input. Please enter a numeric value.")

    # Convert user inputs to DataFrame for prediction
    input_df = pd.DataFrame([user_inputs])

    # Predicting sales using the best model
    predicted_sales = model.predict(input_df)
    return predicted_sales[0]

def main():
    filepath = '/content/Advertising Budget and Sales.csv'
    print("Starting the data analysis process...")
    print(f"Reading data from: {filepath}")

    # Read the data from the CSV file
    df = ReadData(filepath)
    if df.empty:
        print("No data available to process. Please check the file path and contents.")
        return
    else:
        print("Data successfully read into DataFrame.")

    # Clean the data by removing any rows with missing values
    print("Cleaning data...")
    df = CleanData(df)
    if df.empty:
        print("All data was removed after cleaning. Check your data for too many missing values.")
        return
    else:
        print("Data cleaning complete. Missing values removed.")

    # Generate and display summary statistics for the data
    print("Generating summary statistics for the dataset...")
    stats_df = SummaryStatistics(df)
    print(stats_df)

    #Plot the distribution for each advertising channel
    print("\nVisualizing distribution for key metrics...")
    for avenue in ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']:
        PlotDistribution(df, avenue, 'histogram')

    # Compute and plot the correlation matrix using all methods
    print("Computing correlation matrices...")
    correlation_matrices = ComputeCorrelationMatrix(df)
    for method, matrix in correlation_matrices.items():
        print(f"\nDisplaying {method.capitalize()} correlation heatmap...")
        PlotCorrelationHeatmap(matrix, method)

    # Create interaction features and update the dataframe
    print("Creating interaction features between advertising channels...")
    df, new_features = CreateInteractionFeatures(df)
    print("Newly created features: ", new_features)

    # Prepare feature list for modeling and train multiple models
    print("Training multiple regression models to predict sales...")
    feature_list = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    model_performance = TrainMultipleModels(df, 'Sales ($)', feature_list)
    for model_name, metrics in model_performance.items():
        print(f"{model_name}: R_squared = {metrics['R_squared']}, RMSE = {metrics['RMSE']}")

    # Select the best model based on RMSE and print its performance metrics
    print("Selecting the best model based on RMSE...")
    best_model_name, best_model_info = SelectBestModel(model_performance)
    print(f"Best Model: {best_model_name}\nPerformance Metrics: {best_model_info}")

    # Plot feature importances if the model supports this attribute
    best_model = best_model_info['model']
    if hasattr(best_model, 'feature_importances_'):
        print("Plotting feature importances...")
        plot_feature_importance(best_model, feature_list)

    # Define test sets for model validation and plotting residuals
    X_test = df[feature_list]
    y_test = df['Sales ($)']
    print("Plotting residuals to analyze the discrepancies between actual and predicted values...")
    plot_residuals(best_model, X_test, y_test)

    # Display model validation metrics
    print("Validating model with various performance metrics...")
    model_validation_metrics(best_model, X_test, y_test)

    # Perform KMeans clustering and plot clusters
    print("Applying KMeans clustering to identify patterns...")
    optimal_clusters, labels = KMeansClustering(df, 'TV Ad Budget ($)', 'Radio Ad Budget ($)')
    print(f"Optimal number of clusters determined: {optimal_clusters}")
    PlotClusters(df, 'TV Ad Budget ($)', 'Radio Ad Budget ($)', labels)
    optimal_clusters, labels = KMeansClustering(df, 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)')
    print(f"Optimal number of clusters determined: {optimal_clusters}")
    PlotClusters(df, 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)', labels)
    optimal_clusters, labels = KMeansClustering(df, 'TV Ad Budget ($)', 'Newspaper Ad Budget ($)')
    print(f"Optimal number of clusters determined: {optimal_clusters}")
    PlotClusters(df, 'TV Ad Budget ($)', 'Newspaper Ad Budget ($)', labels)

    # Simulate the impact of advertising on sales
    print("Simulating the impact of different advertising budgets on product sales...")
    simulation_results = SimulateAdvertisingImpact(df, best_model, feature_list)
    print(simulation_results[[col for col in simulation_results.columns if 'Simulated_Sales' in col]].head())

    # Plot the impact of each advertising channel on sales
    print("\nPlotting individual channel effects...")
    plot_each_visualization(df)
    print("Visualizing the Sankey diagram of advertising spend to sales...")
    PlotSankeyDiagram(df)

    # Plot all channels vs sales on the same axis
    print("Plotting all channels vs sales on the same axis...")
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    plot_all_channels_vs_sales(df, 'Sales ($)', channels)

    #Plots the total spent in advertising vs sales
    plot_dynamic_visualization(df)


    best_model = model_performance['LinearRegression']['model']  # Placeholder for your best model
    total_budget = 100000  # Total budget for example
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    impact = advertising_combinations_impact(df, channels)

    # Sort combinations by their impact
    sorted_impact = sorted(impact.items(), key=lambda x: x[1], reverse=True)

    # Display the sorted impact
    for combo, imp in sorted_impact:
        print(f"Combination: {combo}, Impact on sales: {imp:.2f}")

    best_model = SelectBestModel(model_performance)[1]['model']

    # Ask user for their total budget
    total_budget = float(input("Enter your total advertising budget: "))

    # Calculate budget allocation
    feature_names = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    allocation = allocate_optimal_budget(best_model, total_budget, feature_names)
    if allocation:
        print("\nRecommended Budget Allocation:")
        for channel, budget in allocation.items():
            print(f"{channel}: ${budget:.2f}")

        # Ask user if they would like to accept this budget allocation.
        accept_allocation = input("Would you like to accept this recommended budget allocation? (yes/no): ").strip().lower()
        if accept_allocation == "yes":
            print("\n--- Sales Prediction based on Recommended Advertising Spend ---")
            # Prepare DataFrame from recommended budget allocation for prediction.
            recommended_input_df = pd.DataFrame([allocation])
            predicted_sales = best_model.predict(recommended_input_df)[0]  # Predict sales based on the recommended allocation.
            print(f"Predicted Sales with Recommended Budget: ${predicted_sales:.2f}")
        elif accept_allocation == "no":
            print("You have chosen not to accept the recommended budget allocation.")
            # ask the user to input their own budget values or end interaction.
            print("Please input your own budget values for a new sales prediction or adjust your strategy as needed.")
            print("\n--- Sales Prediction based on your Advertising Spend ---")
            predicted_sales = predict_user_input_sales(best_model)
            print(f"Predicted Sales: ${predicted_sales:.2f}")
        else:
            print("Invalid input. Please respond with 'yes' or 'no'.")
    else:
        print("Unable to allocate budget due to unsupported model type.")

if __name__ == "__main__":
    main()

import unittest
from sklearn.model_selection import cross_val_score

class TestDataFunctions(unittest.TestCase):
    def setUp(self):
        # Sample data to be used in tests
        self.data = pd.DataFrame({
            'TV': [230.1, 44.5, 17.2, 151.5, 180.8],
            'Radio': [37.8, 39.3, 45.9, 41.3, 10.8],
            'Newspaper': [69.2, 45.1, 69.3, 58.5, 58.4],
            'Sales': [22.1, 10.4, 9.3, 18.5, 12.9]
        })


    def test_CleanData(self):
        # Test case to ensure data cleaning removes rows with NaN values
        data_with_na = self.data.copy()
        data_with_na.loc[1, 'TV'] = np.nan
        cleaned_data = CleanData(data_with_na)
        self.assertEqual(cleaned_data.isna().sum().sum(), 0, "Data cleaning should remove all NaN values")

    def test_SummaryStatistics(self):
        summary_stats = SummaryStatistics(self.data)
        # Ensure 'TV' is a row index, not a column
        self.assertIn('TV', summary_stats.index, "DataFrame should include 'TV' as a row index")
        expected_mean_tv = self.data['TV'].mean()
        calculated_mean_tv = summary_stats.loc['TV', 'mean']
        self.assertAlmostEqual(calculated_mean_tv, expected_mean_tv, places=2, msg="Mean of TV should be calculated correctly")


    def test_ComputeCorrelationMatrix(self):
        # Test case to check correlation calculation
        corr_matrix = ComputeCorrelationMatrix(self.data)
        expected_corr = self.data.corr()
        pd.testing.assert_frame_equal(corr_matrix['pearson'], expected_corr, "Pearson correlation matrix should be calculated correctly")

class TestModelFunctions(unittest.TestCase):
    def setUp(self):
        # Sample data similar to the above setup
        self.data = pd.DataFrame({
            'TV': [230.1, 44.5, 17.2, 151.5, 180.8],
            'Radio': [37.8, 39.3, 45.9, 41.3, 10.8],
            'Newspaper': [69.2, 45.1, 69.3, 58.5, 58.4],
            'Sales': [22.1, 10.4, 9.3, 18.5, 12.9]
        })

    def test_SelectBestModel(self):
        # Test case to ensure the best model is selected based on RMSE
        model_perf = {
            'LinearRegression': {'RMSE': 1.5, 'model': None},
            'SVR': {'RMSE': 2.0, 'model': None}
        }
        best_model_name, _ = SelectBestModel(model_perf)
        self.assertEqual(best_model_name, 'LinearRegression', "Best model should be selected based on the lowest RMSE")

class TestAnalysisFunctions(unittest.TestCase):
    def setUp(self):
        # Sample data to be used in tests
        self.data = pd.DataFrame({
            'A': np.random.normal(0, 1, 100),
            'B': np.random.normal(0, 1, 100),
            'C': np.random.normal(0, 1, 100)
        })

    def test_ComputeCorrelationMatrix(self):
        """Test the ComputeCorrelationMatrix function."""
        corr_matrix = ComputeCorrelationMatrix(self.data)
        self.assertIsInstance(corr_matrix, dict, "Output should be a dictionary")
        self.assertIn('pearson', corr_matrix, "Dictionary should include 'pearson'")
        self.assertTrue(corr_matrix['pearson'].shape[0] == corr_matrix['pearson'].shape[1], "Matrix should be square")
        self.assertTrue(corr_matrix['pearson'].shape[0] == len(self.data.columns), "Matrix size should match the number of DataFrame columns")

    def test_PlotCorrelationHeatmap(self):
        """Test the PlotCorrelationHeatmap function."""
        corr_matrix = ComputeCorrelationMatrix(self.data)['pearson']
        try:
            PlotCorrelationHeatmap(corr_matrix, 'pearson')
        except Exception as e:
            self.fail(f"PlotCorrelationHeatmap raised an exception {e}")

def create_interaction_features(dataframe):
    """Creates interaction features between specified channels and returns the updated dataframe and a list of new feature names."""
    channels = ['TV Ad Budget ($)', 'Radio Ad Budget ($)', 'Newspaper Ad Budget ($)']
    new_features = []
    for i in range(len(channels)):
        for j in range(i + 1, len(channels)):
            feature_name = f"{channels[i]}_{channels[j]}"
            dataframe[feature_name] = dataframe[channels[i]] * dataframe[channels[j]]
            new_features.append(feature_name)  # Add only new interaction features
    dataframe['Total_Spend'] = dataframe[channels].sum(axis=1)
    new_features.append('Total_Spend')  # Include 'Total_Spend' as a new feature
    return dataframe, new_features

class TestInteractionFunctions(unittest.TestCase):
    def setUp(self):
        # Setup a DataFrame with known values for predictable outputs
        self.data = pd.DataFrame({
            'TV Ad Budget ($)': [200, 150, 100],
            'Radio Ad Budget ($)': [30, 20, 10],
            'Newspaper Ad Budget ($)': [40, 30, 20],
        })

    def test_create_interaction_features(self):
        """Test the creation and correctness of interaction features and total spend."""
        updated_data, new_features = create_interaction_features(self.data.copy())

        # Expected results for interaction features
        expected_interactions = {
            'TV Ad Budget ($)_Radio Ad Budget ($)': [6000, 3000, 1000],  # 200*30, 150*20, 100*10
            'TV Ad Budget ($)_Newspaper Ad Budget ($)': [8000, 4500, 2000],  # 200*40, 150*30, 100*20
            'Radio Ad Budget ($)_Newspaper Ad Budget ($)': [1200, 600, 200]  # 30*40, 20*30, 10*20
        }

        # Expected total spend
        expected_total_spend = [270, 200, 130]  # Sum of all budgets per row

        # Check the creation of each interaction feature
        for feature, expected_values in expected_interactions.items():
            try:
                pd.testing.assert_series_equal(updated_data[feature], pd.Series(expected_values),
                                               check_names=False, check_dtype=False)
            except AssertionError:
                self.fail(f"{feature} values are incorrect. Expected {expected_values}, got {updated_data[feature].tolist()}")

        # Check the creation and correctness of the total spend feature
        try:
            pd.testing.assert_series_equal(updated_data['Total_Spend'], pd.Series(expected_total_spend),
                                           check_names=False, check_dtype=False)
        except AssertionError:
            self.fail("Total_Spend values are incorrect. Expected {expected_total_spend}, got {updated_data['Total_Spend'].tolist()}")

        # Additional checks to ensure no unexpected columns were created
        expected_columns = list(self.data.columns) + list(expected_interactions.keys()) + ['Total_Spend']
        self.assertCountEqual(updated_data.columns, expected_columns, "Unexpected columns in the DataFrame.")

class TestMarketingFunctions(unittest.TestCase):
    def setUp(self):
        """Create a DataFrame to use in tests."""
        self.data = pd.DataFrame({
            'A': range(10),
            'B': [x**2 for x in range(10)]
        })

    def test_PerformTTest(self):
        """Test that PerformTTest returns a p-value."""
        # Adding some random noise to make it a fair test
        self.data['C'] = self.data['A'] + np.random.normal(0, 1, 10)
        p_value = PerformTTest(self.data, 'A', 'C')
        self.assertIsInstance(p_value, float)
        self.assertGreaterEqual(p_value, 0)  # p-value should be a non-negative number

    def test_allocate_optimal_budget(self):
        """Test that allocate_optimal_budget returns the correct budget allocation based on coefficients."""
        model = LinearRegression()
        model.fit(self.data[['A']], self.data['B'])
        model.coef_ = np.array([1])  # Simulating a coefficient for simplicity
        budget = 100
        allocation = allocate_optimal_budget(model, budget, ['A'])
        self.assertEqual(allocation, {'A': 100})

if __name__ == '__main__':
    unittest.main(argv=['first-arg-is-ignored'], exit=False)
